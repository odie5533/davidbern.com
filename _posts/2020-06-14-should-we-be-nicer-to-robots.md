---
layout: post
title:  Should We Be Nicer To Robots?
date:   2020-06-14 12:00:00
description: 
tags: 
categories: Technology
---
I’d like to start off today’s story with a quote from one of <a href="http://www.katedarling.org/" target="_blank">Kate Darling</a>’s <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2588669" target="_blank">papers</a> on Anthropomorphic Framing in Human-Robot Interaction:

<blockquote>
People have a tendency to <b>project life-like qualities onto robots</b>.  As we increasingly create spaces where robotic technology interacts  with humans, this inclination raises ethical questions around use and  policy. A human-robot-interaction experiment conducted in our lab  indicates that framing robots through anthropomorphic language (like a  personified name or story) can impact how people perceive and treat a  robot. … I discuss concerns about anthropomorphizing robotic technology  in certain contexts, but argue that there are also cases where  encouraging anthropomorphism is desirable.
</blockquote>

Two quick definitions according to Wikipedia, just so there’s no confusion: <b>A robot</b> is a machine capable of carrying out a complex series of actions automatically. <b>Anthropomorphization</b> is the attribution of human-like traits or form to non-human beings  (e.g. “seeing” a face in the front of a car). If you’ve already started  falling asleep after those first few lines: Don’t worry, what follows  will be rather unscientific!

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/robot.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

So, I came across this topic while watching <a href="https://medium.com/u/119b8eb57f8e?source=post_page-----d663f48737fe-----------------------------------" target="_blank">Lex Fridman</a>’s <a href="https://www.youtube.com/watch?v=7KTbEn7PiaY" target="_blank">talk with Kate Darling on YouTube</a> a couple of days ago and it got me thinking. For example, Lex Fridman mentioned that he makes a conscious effort to say “please” whenever he’s asking something of a robot. Do you do that too? I certainly don’t. However, I don’t really talk to robots that often, so there’s that.

The  actual question here is: Why should you bother being nice to a robot?  As far as we’re concerned, they don’t have any feelings. However, one of  many good points that was brought up in the talk was that being nice to  robots might train our “empathy muscle”, while treating them badly  might result in the very opposite – we then might go on and transfer  that behavior over to human interaction. Also, treating things badly  really has few upsides in general (did shouting at your computer ever  help?). So maybe the question should be: Why <em>shouldn’t</em> you  bother being nice to a robot? In the end, it doesn’t really cost you  anything other than a fraction of a second to add that “please” to the  end of your sentence, and it might help with keeping you off that  robot’s blacklist if it should happen to actually <em>have</em> feelings. If that really is the case, then that might be the reason why  that robot lawnmower of yours has been trying to kill you ever since  you’ve kicked it for going in the wrong direction.

Anyway, Kate Darling’s paper also mentions that robots are specifically <em>designed</em> to be anthropomorphized, but people will also anthropomorphize robots with non-anthropomorphic  design. I’ve certainly caught myself doing that! However, that might  just be the case because I’ve been primed to do that by seeing likeable  “robots” from my early childhood on, two examples being Microsoft’s  Clippy and C-3PO in Star Wars.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/c3po.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    C3PO from Star Wars!
</div>

Here’s another interesting quote that emphasizes this:


<blockquote>
… a CEO and employees of a company that develops medicine delivery robots  observed hospital staff being friendlier towards robots that had been  given human names. Even tolerance for malfunction was <b>higher</b> with anthropomorphic framing (“Oh, Betsy made a mistake!” vs. “This stupid machine doesn’t work!”).
</blockquote>

I definitely tend to resort to the not-so-nice form of response, so that’s something I’ve got to work on, too…

<h2>Potential for Manipulation</h2>
Robots  are increasingly being put to use in various workplaces, e.g.  manufacturing, transportation systems or the military. Personal  households might follow soon (or already have) and in general we are and  will be exposed to interaction with robots more often.

I  think what’s interesting here is the potential for exploitation:  Assuming that people form some sort of connection with personal  household (or any kind of) robots, would they be more susceptible to  being manipulated by it? If at some point it should go as far as people <em>marrying</em>  their robots (there’s people who marry their dog, so this idea is not  that far fetched) this will certainly be something to think about. Many  manipulative mechanisms are already taking place via various, much  simpler forms of technology which we all know about.

However,  maybe the underlying question is: Is it okay as long as the  manipulation leads to a positive outcome? Is the solution to incentivize  companies to be interested in manipulating an outcome that’s positive  for them but also us and society as a whole? What does a positive  outcome even look like? These questions go much further than the  anthropomorphization of robots of course, which is why I’ll stop here.  What do you think our future interaction with robots will look like? Are  you nice to robots – and if not, <b>why not</b>?

That’s all for this week – thanks for reading!